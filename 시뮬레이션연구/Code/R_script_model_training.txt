# <To Do>
# - Raw Data에 대해 Outlier를 trimming 했을 때의 에러율 결과
# - Mach number, AoA, Renolds number 등 attribute에 대해 각각 최적의 모델을 찾게 될 때의 에러율 결과
# - Mach number, AoA, Renolds number 등 attribute에 대해 구간 별 (interval-wise) 모델에 대한 에러율 결과
#   -> Spline을 의미. 구간을 받아야 함
# - 대표 4개 Machine learning 기법에 더하여, Spline 방식을 추가했을 때의 에러율 결과
#   -> 위와 동일한 의미
# - 추후 제공해 드린 19,000(?) 여건의 추가 데이터를 반영한 training 에러율 결과
# - Airfoil 두께를 새로운 attribute로 추가했을 때의 결과 
# - 각 attribute에 대해 서로 다른 transformation (log, exp 등)을 적용했을 때의 에러율 결과
#  -> 너무 많아 불가. 제안을 받아야 함
# - 서로 다른 Weight가 적용되었을 때의 에러율 결과 (AoA가 가장 중요…)
#  -> 모델에 맡기기로 함
# - 각 대표 기법에서 사용되는 Turning parameter에 대해 서로 다른 값을 고려했을 때 (예. k-NN에서 k=2 이외에 k=3, k=4, … , hidden layer (h)=2 이외에 h=3, h=4, ... 등)의 에러율 결과 
# 
# -------------------------------
# 
# <Dataset>
# * 총건수: 7680건 (실제는 7679건, 1건은 해석안됨(NACA0012/Re4E5/Ma010/AoA000 -> Aerodynamic.dat 파일 없음)
#   - thickness: 9, 10, 11, 12 (4개)
#   - Umach: 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6 (12개)
#   - AOA: 0, 1, 2, 3, 4, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10 (16개)
#   - RE: 100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000 (10개)
#  - 4*12*16*10 = 7680
# 
# <Model Evaluation>
# * Measure: average error(%) = avg(abs(true - estimated)/true for all test data)
# * 10-fold cross validation
#   - all data(7679) = training(6200)(80%) + test(1479)(20%)
#   - training(6200) = training(5580)(90%) + validation(620)(10%) -> 10 times
# 
# -------------------------------
#
# <R Code>
#
# data loading
all_data = read.csv('D:/kflow_data.csv', sep=",", header=TRUE)
head(all_data)
attach(all_data)

# train/test data partition (svmdoc.pdf에도 좋은 코드 예제가 있음)
set.seed(123)
all_data = all_data[sample(nrow(all_data)), ]
train_data = all_data[1:6200, ]
test_data = all_data[6201:nrow(all_data), ]

# multiple linear regression
model = lm(Cl ~ thickness + Umach + AOA + RE, data = train_data)
library(DAAG)
cv.lm(data = train_data, form.lm = model, m = 10)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+8]) # 이상치 개수
mean(errors[errors < 1e+8]) # 이상치 제거 후 평균 오차(%)
# 이상치 존재: (예) thickness = 11, Umach = 0.3, AOA = 0, RE = 4E+05, Cl = 1.12E-14
#Average Error = 12.6% (with outlier removal(# = 92))
summary(model)

# Support vector regression
library(e1071)
model <- svm(Cl ~ thickness + Umach + AOA + RE, data = train_data, cross=10)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+7]) # 이상치 개수
mean(errors[errors < 1e+7]) # 이상치 제거 후 평균 오차(%)
# Average Error = 3.74% (with outlier removal (# = 92))

# CART regression
ibrary(rpart)
model <- rpart(Cl ~ thickness + Umach + AOA + RE, data = train_data, method="anova")
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+8]) # 이상치 개수
mean(errors[errors < 1e+8]) # 이상치 제거 후 평균 오차(%)
# Average Error = 12% (with outlier removal (# = 92))

# Random Forests
library(randomForest)
model <- randomForest(Cl ~ thickness + Umach + AOA + RE, data = train_data)
print(model) # view results 
importance(model) # importance of each predictor
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인 
length(errors[errors > 1e+8]) # 이상치 개수
mean(errors[errors < 1e+8]) # 이상치 제거 후 평균 오차(%)
# Average Error = 13.7% (with outlier removal (# = 92))

# Generalized Boosted Regression (boosted trees)
library(gbm)
model <- gbm(Cl ~ thickness + Umach + AOA + RE, data = train_data, cv.folds=10)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+9]) # 이상치 개수
mean(errors[errors < 1e+9]) # 이상치 제거 후 평균 오차(%)
# Average Error = 54% (with outlier removal (# = 92))

# MARS (Multivariate Adaptive Regression Splines)
library(earth)
model <- earth(Cl ~ thickness + Umach + AOA + RE, data = train_data, nfold=10)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+7]) # 이상치 개수
mean(errors[errors < 1e+7]) # 이상치 제거 후 평균 오차(%)
# Average Error = 10.6% (with outlier removal (# = 92))

# Local regression
library(locfit)
model <- locfit(Cl ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+6]) # 이상치 개수
mean(errors[errors < 1e+6]) # 이상치 제거 후 평균 오차(%)
# Average Error = 4.93% (with outlier removal (# = 92)) (nn=0.7(default))
# Average Error = 2.27% (with outlier removal (# = 92)) (nn=0.2)
# Average Error = 1.51% (with outlier removal (# = 92)) (nn=0.1)

# GAM (Generalized additive models)
library(gam)
model <- gam(Cl ~ s(thickness) + s(Umach) + s(AOA) + s(RE), family=gaussian, data=train_data) 
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+7]) # 이상치 개수
mean(errors[errors < 1e+7) # 이상치 제거 후 평균 오차(%)
# Average Error = 10.6% (with outlier removal (# = 92)) 

# k-NN regression
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x))) }
normalized_train_data = as.data.frame(cbind(lapply(train_data[1:4], normalize), train_data[5:9]))
normalized_test_data = as.data.frame(cbind(lapply(test_data[1:4], normalize), test_data[5:9]))
library(FNN)
predicted_Cl = knn.reg(train = normalized_train_data[, 1:4], test = normalized_test_data[, 1:4], y = normalized_train_data[, 5], k = 10)
errors = abs((test_data$Cl - predicted_Cl$pred)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+2]) # 이상치 개수
mean(errors[errors < 1e+2) # 이상치 제거 후 평균 오차(%)
# Average Error = 15.4% (with outlier removal (# = 41)) (k = 2) (1e+8)
# Average Error = 5.19% (with outlier removal (# = 86)) (k = 3) (1e+2)
# Average Error = 3.81% (with outlier removal (# = 90)) (k = 5) (1e+8)
# Average Error = 3.91% (with outlier removal (# = 92)) (k = 7) (1e+8)
# Average Error = 3.04% (with outlier removal (# = 92)) (k = 10) (1e+8)
# Average Error = 3.79% (with outlier removal (# = 92)) (k = 20) (1e+8)

# Neural networks
library(neuralnet) # fail to converge
libaray(nnet)
# model = nnet(Cl ~ thickness + Umach + AOA + RE, data = normalized_train_data, size = 5, decay = 5e-4)
# predicted_Cl = predict(model, newdata = normalized_test_data)

model = tune.nnet(Cl ~ thickness + Umach + AOA + RE, data = normalized_train_data, size = 5, decay = 5e-4, tune.control(cross = 10))
predicted_Cl = predict(model$best.model, newdata = normalized_test_data)

errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
plot(errors) # 이상치 확인
length(errors[errors > 1e+7]) # 이상치 개수
mean(errors[errors < 1e+7) # 이상치 제거 후 평균 오차(%)
# Average Error = 7.72% (with outlier removal (# = 92)) (size = 3)
# Average Error = 3.65% (with outlier removal (# = 92)) (size = 4)
# Average Error = 3.57% (with outlier removal (# = 92)) (size = 5)
# Average Error = 3.57% (with outlier removal (# = 92)) (size = 6)

# Deep learning (multilayer ANN)
library(h2o)
h2o.init()

train_frame = as.h2o(normalized_train_data)
test_frame = as.h2o(normalized_test_data)
model = h2o.deeplearning(x = 1:4, y = 5, training_frame = train_frame, hidden=c(3, 3), nfolds=10)
predicted_Cl = h2o.predict(model, test_frame)
errors = abs((test_frame$Cl - predicted_Cl)/test_frame$Cl*100)
mean(errors[errors < 1e+7])
# Average Error = 3.14% (with outlier removal (# = 92)) (hidden=c(3,3))
# Average Error = 4.23% (with outlier removal (# = 92)) (hidden=c(4,4))
# Average Error = 1.92% (with outlier removal (# = 92)) (hidden=c(100,100), nfolds=0)
# Average Error = 1.58% (with outlier removal (# = 92)) (hidden=c(100,100), nfolds=10)

# CPU time used
system.time()

# Outliers
outlier_index = which(errors > 1e+6)
outliers = test_data[outlier_index, ]

# <Prediction Models>
# 
# - Note: some methods require "scaling" or "standardization"
#   = https://rstudio-pubs-static.s3.amazonaws.com/170751_5a69557a96ee4fd2949422a71068a431.html
#   = https://rpubs.com/ryankelly/GAMs
# 
# - Linear regression
#   = http://www.statmethods.net/stats/regression.html
# 
# - Support vector machines
#   = ftp://cran.r-project.org/pub/R/web/packages/e1071/vignettes/svmdoc.pdf
#   = e-regression, other kernals, 10-fold cross validation
#   = svm() scales the data by default
# 
# - (Decsion Tree) CART 
#   = rpart(formula, method=anova)
#   = http://www.statmethods.net/advstats/cart.html
#   = http://statweb.stanford.edu/~lpekelis/talks/13_datafest_cart_talk.pdf
# 
# - (Decsion Tree) Random forests
#   = http://www.statmethods.net/advstats/cart.html
# 
# - (Decision Tree) Boosting
#   = http://machinelearningmastery.com/non-linear-regression-in-r-with-decision-trees/
#   = http://www.listendata.com/2015/07/gbm-boosted-models-tuning-parameters.html
# 
# - MARS (Multivariate Adaptive Regression Splines)
#   = https://cran.r-project.org/web/packages/earth/earth.pdf
# 
# - Local regression
#   = locfit, loess
#   = https://fibosworld.wordpress.com/2012/11/04/loess-regression-with-r/
#   = https://en.wikipedia.org/wiki/Local_regression
#   = alpha (smoothing parameter, the smaller, the colser): 0.25~0.5
# 
# - GAM (Generalized additive models)
#   = https://cran.r-project.org/web/packages/gam/gam.pdf
#   = http://www.nrcse.washington.edu/NordicNetwork/GAMlecture.pdf
#   
# - k-nearest neighbor
#   = http://artax.karlin.mff.cuni.cz/r-help/library/FNN/html/knn.reg.html
#   = https://www.datacamp.com/community/tutorials/machine-learning-in-r#gs.RxqXCYo
#   = knn.reg() performs leave one corss-validation if test is not supplied
#   = https://books.google.co.kr/books?id=KOiuCQAAQBAJ&pg=PA104&lpg=PA104&dq=r+%22knn.reg22+regression&source=bl&ots=RDZnfrg1J7&sig=nRZjQuCklNjup9V8z4BBhPsrRh4&hl=en&sa=X&ved=0ahUKEwjSqZTv4KTPAhUE2WMKHWcNAbQQ6AEIVDAJ#v=onepage&q=r%20%22knn.reg%22%20regression&f=false
#   = k = 2, 3, 4, ..., 10
# 
# - Neural networks
#   = https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/
#   = Layers = (4 - 3 - 1) or (4 - 3 - 3 - 1)
#   = hint (http://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)
#     - One hidden layer is sufficient for the large majority of problems.
#     - the optimal size of the hidden layer is usually between the size of the input and size of the output layers
#   = # of hidden layers
#     - 0 - Only capable of representing linear separable functions or decisions.
#     - 1 - Can approximate any function that contains a continuous mapping from one finite space to another.
#     - 2 - Can represent an arbitrary decision boundary to arbitrary accuracy with rational activation functions and can approximate any smooth mapping to any accuracy.
#   = # of neurons
#     - The number of hidden neurons should be between the size of the input layer and the size of the output layer.
#     - The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.
#     - The number of hidden neurons should be less than twice the size of the input layer.
# 
# -------------------------------

model <- locfit(Cl ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cl = predict(model, newdata = test_data)
errors = abs((test_data$Cl - predicted_Cl)/test_data$Cl*100)
length(errors[errors > 1e+6]) 

model <- locfit(Cdt ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cdt = predict(model, newdata = test_data)
errors = abs((test_data$Cdt - predicted_Cdt)/test_data$Cdt*100)
mean(errors)

model <- locfit(Cdp ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cdp = predict(model, newdata = test_data)
errors = abs((test_data$Cdp - predicted_Cdp)/test_data$Cdp*100)
mean(errors)

model <- locfit(Cdf ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cdf = predict(model, newdata = test_data)
errors = abs((test_data$Cdf - predicted_Cdf)/test_data$Cdf*100)
mean(errors)

model <- locfit(Cm ~ lp(thickness, Umach, AOA, RE, scale=TRUE, nn=0.005), data = train_data)
predicted_Cm = predict(model, newdata = test_data)
errors = abs((test_data$Cm - predicted_Cm)/test_data$Cm*100)
length(errors[errors > 1e+3])
mean(errors[errors < 1e+3])

results = cbind(test_data$thickness, test_data$Umach, test_data$AOA, test_data$RE)
head(results)
results = cbind(test_data$thickness, test_data$Umach, test_data$AOA, test_data$RE, test_data$Cl, predicted_Cl, test_data$Cdt, predicted_Cdt, test_data$Cdp, predicted_Cdp, test_data$Cdf, predicted_Cdf, test_data$Cm, predicted_Cm)
write.csv(results, "D:/predicted_values.csv")

